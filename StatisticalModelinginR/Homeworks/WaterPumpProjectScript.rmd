---
title: "WaterPumpProject"
author: "Kamryn Parker, Cameron Beavers, Ryan Ratermann"
date: "2/4/2021"
output: html_document
---

```{r}
library(dplyr)
trainlabel = read.csv("TrainingSetLabels.csv",header=TRUE)
trainset = read.csv("TrainingSetValues.csv",header=TRUE)
TrainingSetJoin = trainlabel %>% inner_join(trainset)
testset = read.csv('TestSetValues.csv',header=TRUE)

write.csv(TrainingSetJoin,'TrainingSetJoinValues.csv')
```

```{r}
library(e1071)
library(tidyverse)
library(tidymodels)
#Support Vector Machine

TrainingSetJoin <- TrainingSetJoin %>% drop_na(amount_tsh, longitude, latitude, num_private, region_code, district_code, population, construction_year) 

TrainingSetJoin
```
```{r}
svmfit <- svm(status_group ~ amount_tsh + longitude + latitude + num_private + region_code + district_code + population + construction_year, data = TrainingSetJoin, kernel = "radial", cost = 5, scale = FALSE )
print(svmfit)
```
```{r}
library(caret)
confusionMatrix(TrainingSetJoin$status_group, predict(svmfit))
```
```{r}
testsetdf = testset = read.csv('TestSetValuesNonNumeric.csv',header=TRUE)

testsetdf <- subset(testsetdf, select = c(status_group, amount_tsh, longitude, latitude, num_private, region_code, district_code, population, construction_year))

testsetdf <- testsetdf%>% drop_na(amount_tsh, longitude, latitude, num_private, region_code, district_code, population)

svmfit_test <- svm(status_group ~ amount_tsh + longitude + latitude + num_private + region_code + district_code + population + construction_year, data = testsetdf, kernel = "radial", cost = 5, scale = FALSE )

testsetdf$prediciton <- predict(svmfit_test)
```

```{r}
row <- testsetdf$prediciton
write.csv(row,'Y_prediction_new.csv')
```


```{r}
#Scaling and Tuning
df <- read.csv("TrainSetNumeric.csv",header=TRUE)

df <- subset(df, select = c(status_group, amount_tsh, longitude, latitude, num_private, region_code, district_code, population))

df <- df %>% drop_na(amount_tsh, longitude, latitude, num_private, region_code, district_code, population)

df

train_test_split_index <- 0.8 * nrow(df)

train <- df[1:train_test_split_index,]
test <- df[(train_test_split_index+1): nrow(df),]

X_train <- scale(train[, c(2:8)])

y_train <- train$status_group
dim(y_train) <- c(length(y_train), 1) # add extra dimension to vector

X_test <- scale(test[, c(2:8)])

y_test <- test$status_group
dim(y_test) <- c(length(y_test), 1) # add extra dimension to vector
```

```{r}
X_train <- as.matrix(X_train, byrow=TRUE)
X_train <- t(X_train)
y_train <- as.matrix(y_train, byrow=TRUE)
y_train <- t(y_train)

X_test <- as.matrix(X_test, byrow=TRUE)
X_test <- t(X_test)
y_test <- as.matrix(y_test, byrow=TRUE)
y_test <- t(y_test)
```

```{r}
getLayerSize <- function(X, y, hidden_neurons, train=TRUE) {
  n_x <- dim(X)[1]
  n_h <- hidden_neurons
  n_y <- dim(y)[1]   
  
  size <- list("n_x" = n_x,
               "n_h" = n_h,
               "n_y" = n_y)
  
  return(size)
}

layer_size <- getLayerSize(X_train, y_train, hidden_neurons = 4)
layer_size
```


```{r}
initializeParameters <- function(X, list_layer_size){

    m <- dim(data.matrix(X))[2]
    
    n_x <- list_layer_size$n_x
    n_h <- list_layer_size$n_h
    n_y <- list_layer_size$n_y
        
    W1 <- matrix(runif(n_h * n_x), nrow = n_h, ncol = n_x, byrow = TRUE) * 0.01
    b1 <- matrix(rep(0, n_h), nrow = n_h)
    W2 <- matrix(runif(n_y * n_h), nrow = n_y, ncol = n_h, byrow = TRUE) * 0.01
    b2 <- matrix(rep(0, n_y), nrow = n_y)
    
    params <- list("W1" = W1,
                   "b1" = b1, 
                   "W2" = W2,
                   "b2" = b2)
    
    return (params)
}
```

```{r}
init_params <- initializeParameters(X_train, layer_size)
lapply(init_params, function(x) dim(x))

sigmoid <- function(x){
    return(1 / (1 + exp(-x)))
}
```

```{r}
forwardPropagation <- function(X, params, list_layer_size){
    
    m <- dim(X)[2]
    n_h <- list_layer_size$n_h
    n_y <- list_layer_size$n_y
    
    W1 <- params$W1
    b1 <- params$b1
    W2 <- params$W2
    b2 <- params$b2
    
    b1_new <- matrix(rep(b1, m), nrow = n_h)
    b2_new <- matrix(rep(b2, m), nrow = n_y)
    
    Z1 <- W1 %*% X + b1_new
    A1 <- sigmoid(Z1)
    Z2 <- W2 %*% A1 + b2_new
    A2 <- sigmoid(Z2)
    
    cache <- list("Z1" = Z1,
                  "A1" = A1, 
                  "Z2" = Z2,
                  "A2" = A2)

    return (cache)
}

fwd_prop <- forwardPropagation(X_train, init_params, layer_size)
lapply(fwd_prop, function(x) dim(x))
```


```{r}
computeCost <- function(X, y, cache) {
    m <- dim(X)[2]
    A2 <- cache$A2
    logprobs <- (log(A2) * y) + (log(1-A2) * (1-y))
    cost <- -sum(logprobs/m)
    return (cost)
}
cost <- computeCost(X_train, y_train, fwd_prop)
cost
```

```{r}
backwardPropagation <- function(X, y, cache, params, list_layer_size){
    
    m <- dim(X)[2]
    
    n_x <- list_layer_size$n_x
    n_h <- list_layer_size$n_h
    n_y <- list_layer_size$n_y

    A2 <- cache$A2
    A1 <- cache$A1
    W2 <- params$W2

    dZ2 <- A2 - y
    dW2 <- 1/m * (dZ2 %*% t(A1)) 
    db2 <- matrix(1/m * sum(dZ2), nrow = n_y)
    db2_new <- matrix(rep(db2, m), nrow = n_y)
    
    dZ1 <- (t(W2) %*% dZ2) * (1 - A1^2)
    dW1 <- 1/m * (dZ1 %*% t(X))
    db1 <- matrix(1/m * sum(dZ1), nrow = n_h)
    db1_new <- matrix(rep(db1, m), nrow = n_h)
    
    grads <- list("dW1" = dW1, 
                  "db1" = db1,
                  "dW2" = dW2,
                  "db2" = db2)
    
    return(grads)
}

back_prop <- backwardPropagation(X_train, y_train, fwd_prop, init_params, layer_size)
lapply(back_prop, function(x) dim(x))
```

```{r}
updateParameters <- function(grads, params, learning_rate){

    W1 <- params$W1
    b1 <- params$b1
    W2 <- params$W2
    b2 <- params$b2
    
    dW1 <- grads$dW1
    db1 <- grads$db1
    dW2 <- grads$dW2
    db2 <- grads$db2
    
    
    W1 <- W1 - learning_rate * dW1
    b1 <- b1 - learning_rate * db1
    W2 <- W2 - learning_rate * dW2
    b2 <- b2 - learning_rate * db2
    
    updated_params <- list("W1" = W1,
                           "b1" = b1,
                           "W2" = W2,
                           "b2" = b2)
    
    return (updated_params)
}

update_params <- updateParameters(back_prop, init_params, learning_rate = 0.01)
lapply(update_params, function(x) dim(x))
```

```{r}
trainModel <- function(X, y, num_iteration, hidden_neurons, lr){

    layer_size <- getLayerSize(X, y, hidden_neurons)
    init_params <- initializeParameters(X, layer_size)
    cost_history <- c()
    for (i in 1:num_iteration) {
        fwd_prop <- forwardPropagation(X, init_params, layer_size)
        cost <- computeCost(X, y, fwd_prop)
        back_prop <- backwardPropagation(X, y, fwd_prop, init_params, layer_size)
        update_params <- updateParameters(back_prop, init_params, learning_rate = lr)
        init_params <- update_params
        cost_history <- c(cost_history, cost)

        if (i %% 10000 == 0) cat("Iteration", i, " | Cost: ", cost, "\n")
    }

    model_out <- list("updated_params" = update_params,
                      "cost_hist" = cost_history)
    return (model_out)
}
EPOCHS = 5000
HIDDEN_NEURONS = 40
LEARNING_RATE = 0.9

train_model <- trainModel(X_train, y_train, hidden_neurons = HIDDEN_NEURONS, num_iteration = EPOCHS, lr = LEARNING_RATE)

```

```{r}
makePrediction <- function(X, y, hidden_neurons){
    layer_size <- getLayerSize(X, y, hidden_neurons)
    params <- train_model$updated_params
    fwd_prop <- forwardPropagation(X, params, layer_size)
    pred <- fwd_prop$A2
    
    return (pred)
}

y_pred <- makePrediction(X_test, y_test, HIDDEN_NEURONS)
y_pred <- round(y_pred)

tb_nn <- table(y_test, y_pred)

acc <- (tb_nn[1] + tb_nn[4])/(tb_nn[1] + tb_nn[2] + tb_nn[3] + tb_nn[4])
recall <- tb_nn[4]/(tb_nn[4] + tb_nn[3])
precision <- tb_nn[4]/(tb_nn[4] + tb_nn[2])
f1 <- 2 * ((precision * recall) / (precision + recall))

acc
```

```{r}
plot(train_model$cost_hist, col = "blue", xlab = "EPOCHS", ylab = "Cost HIstory", main = "Cost History")
```

```{r}
testsetnew = testset = read.csv('TestSetValues.csv',header=TRUE)

testsetnew <- subset(testsetnew, select = c(status_group, amount_tsh, longitude, latitude, num_private, region_code, district_code, population))

testsetnew <- testsetnew %>% drop_na(amount_tsh, longitude, latitude, num_private, region_code, district_code, population)


X_test_actual <- scale(testsetnew[, c(2:8)])

y_test_actual <- testsetnew$status_group


X_test_actual <- as.matrix(X_test_actual, byrow=TRUE)
X_test_actual <- t(X_test_actual)
y_test_actual <- as.matrix(y_test_actual, byrow=TRUE)
y_test_actual <- t(y_test_actual)

y_pred_actual <- makePrediction(X_test_actual, y_test_actual, HIDDEN_NEURONS)
y_pred_actual <- round(y_pred_actual)


```

```{r}
library(reshape)
new <- t(y_pred_actual)
write.csv(new,'Y_prediction.csv')
```

